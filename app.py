import streamlit as st
from datetime import datetime
from googletrans import Translator
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import warnings
import time
warnings.filterwarnings("ignore")

# Page configuration
st.set_page_config(
    page_title="‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å", 
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'current_model' not in st.session_state:
    st.session_state.current_model = None
if 'translator' not in st.session_state:
    st.session_state.translator = None
if 'language' not in st.session_state:
    st.session_state.language = 'Telugu'  # Default language

# Set default values for removed sidebar options
model_choice = "Auto (Recommended)"
response_language = "Telugu & English" if st.session_state.language == 'English' else "Telugu Only"

# Language toggle button at top right
col_left, col_right = st.columns([4, 1])
with col_right:
    if st.button(f"üåê {st.session_state.language}", help="Click to switch language"):
        st.session_state.language = 'English' if st.session_state.language == 'Telugu' else 'Telugu'
        st.rerun()

# Custom CSS for better UI
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #2a5298;
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 4px solid #9c27b0;
    }
    .stSelectbox > div > div {
        background-color: #ffffff !important;
        border: 2px solid #2a5298 !important;
        border-radius: 10px !important;
        color: #000000 !important;
    }
    .stSelectbox > div > div > div {
        color: #000000 !important;
        font-weight: 500 !important;
    }
    .stSelectbox label {
        color: #2a5298 !important;
        font-weight: bold !important;
        font-size: 16px !important;
    }
    .stTextArea > div > div > textarea {
        background-color: #f8f9fa;
        border-radius: 10px;
        border: 2px solid #e9ecef;
        font-size: 16px;
    }
    .legal-disclaimer {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #ff9800;
        margin-top: 2rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stButton > button {
        background: linear-gradient(90deg, #2a5298 0%, #1e3c72 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: bold;
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    .feature-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
</style>
""", unsafe_allow_html=True)

# Title and header
if st.session_state.language == 'Telugu':
    st.markdown("""
    <div class="main-header">
        <h1>‚öñÔ∏è ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h1>
        <p>‡∞ï‡±É‡∞§‡±ç‡∞∞‡∞ø‡∞Æ ‡∞Æ‡±á‡∞ß‡∞∏‡±ç‡∞∏‡±Å ‡∞Ü‡∞ß‡∞æ‡∞∞‡∞ø‡∞§ ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞ï‡∞§‡±ç‡∞µ‡∞Ç</p>
        <small>Microsoft DialoGPT-Large + Google FLAN-T5 ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞µ‡∞Ç‡∞§‡∞Ç | 8GB RAM ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡±Ä‡∞ï‡±É‡∞§‡∞Ç</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Legal question categories
    st.subheader("üìã ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞æ‡∞≤‡±Å")
else:
    st.markdown("""
    <div class="main-header">
        <h1>‚öñÔ∏è Legal Assistant AI Chatbot</h1>
        <p>AI-Powered Legal Guidance & Information System</p>
        <small>Powered by Microsoft DialoGPT-Large + Google FLAN-T5 | Optimized for 8GB RAM</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Legal question categories
    st.subheader("üìã Legal Categories")

legal_categories_telugu = {
    "‡∞ï‡±ç‡∞∞‡∞ø‡∞Æ‡∞ø‡∞®‡∞≤‡±ç ‡∞≤‡∞æ": [
        "FIR ‡∞¶‡∞æ‡∞ñ‡∞≤‡±Å ‡∞ö‡±á‡∞∏‡±á ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞Ö‡∞∞‡±Ü‡∞∏‡±ç‡∞ü‡±Å ‡∞Ö‡∞Ø‡∞ø‡∞® ‡∞µ‡±ç‡∞Ø‡∞ï‡±ç‡∞§‡∞ø ‡∞π‡∞ï‡±ç‡∞ï‡±Å‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?", 
        "‡∞¨‡±Ü‡∞Ø‡∞ø‡∞≤‡±ç ‡∞é‡∞≤‡∞æ ‡∞Ö‡∞™‡±ç‡∞≤‡±à ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞Ö‡∞Ç‡∞§‡∞ø‡∞∏‡∞ø‡∞™‡±á‡∞ü‡∞∞‡±Ä ‡∞¨‡±Ü‡∞Ø‡∞ø‡∞≤‡±ç ‡∞Ö‡∞Ç‡∞ü‡±á ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞™‡±ã‡∞≤‡±Ä‡∞∏‡±Å ‡∞ï‡∞∏‡±ç‡∞ü‡∞°‡±Ä‡∞≤‡±ã ‡∞π‡∞ï‡±ç‡∞ï‡±Å‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞∏‡±à‡∞¨‡∞∞‡±ç ‡∞ï‡±ç‡∞∞‡±à‡∞Æ‡±ç ‡∞é‡∞≤‡∞æ ‡∞®‡∞ø‡∞µ‡±á‡∞¶‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?",
        "‡∞¶‡∞π‡±á‡∞ú‡±ç ‡∞µ‡±á‡∞ß‡∞ø‡∞Ç‡∞™‡±Å‡∞≤ ‡∞µ‡∞ø‡™∑‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞è‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?"
    ],
    "‡∞∏‡∞ø‡∞µ‡∞ø‡∞≤‡±ç ‡∞≤‡∞æ": [
        "‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞≤ ‡∞µ‡∞ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?",
        "‡∞ï‡∞æ‡∞Ç‡∞ü‡±ç‡∞∞‡∞æ‡∞ï‡±ç‡∞ü‡±ç ‡∞â‡∞≤‡±ç‡∞≤‡∞Ç‡∞ò‡∞® ‡∞ï‡±á‡∞∏‡±Å ‡∞é‡∞≤‡∞æ ‡∞¶‡∞æ‡∞ñ‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞á‡∞Ç‡∞ú‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞é‡∞≤‡∞æ ‡∞™‡±ä‡∞Ç‡∞¶‡∞æ‡∞≤‡∞ø?",
        "‡∞®‡∞∑‡±ç‡∞ü‡∞™‡∞∞‡∞ø‡∞π‡∞æ‡∞∞‡∞Ç ‡∞é‡∞≤‡∞æ ‡∞ï‡±ç‡∞≤‡±Ü‡∞Ø‡∞ø‡∞Æ‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞Ö‡∞¶‡±ç‡∞¶‡±Ü ‡∞µ‡∞ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?",
        "‡∞™‡±ä‡∞∞‡±Å‡∞ó‡±Å‡∞µ‡∞æ‡∞∞‡∞ø‡∞§‡±ã ‡∞µ‡∞ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å ‡∞é‡∞≤‡∞æ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?"
    ],
    "‡∞ï‡±Å‡∞ü‡±Å‡∞Ç‡∞¨ ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø‡∞Ç": [
        "‡∞µ‡∞ø‡∞°‡∞æ‡∞ï‡±Å‡∞≤ ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞≤ ‡∞ï‡∞∏‡±ç‡∞ü‡∞°‡±Ä ‡∞ö‡∞ü‡±ç‡∞ü‡∞æ‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞µ‡∞ø‡∞µ‡∞æ‡∞π ‡∞∞‡∞¶‡±ç‡∞¶‡±Å ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞ó‡±É‡∞π ‡∞π‡∞ø‡∞Ç‡∞∏ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞∞‡∞ï‡±ç‡∞∑‡∞£ ‡∞é‡∞≤‡∞æ ‡∞™‡±ä‡∞Ç‡∞¶‡∞æ‡∞≤‡∞ø?",
        "‡∞≠‡∞∞‡∞£ ‡∞≠‡∞§‡±ç‡∞Ø‡∞Ç ‡∞é‡∞≤‡∞æ ‡∞ï‡±ç‡∞≤‡±Ü‡∞Ø‡∞ø‡∞Æ‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞™‡±Ü‡∞≥‡±ç‡∞≤‡∞ø ‡∞∞‡∞ø‡∞ú‡∞ø‡∞∏‡±ç‡∞ü‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?"
    ],
    "‡∞Ü‡∞∏‡±ç‡∞§‡∞ø ‡∞ö‡∞ü‡±ç‡∞ü‡∞Ç": [
        "‡∞á‡∞ö‡±ç‡∞õ‡∞æ‡∞™‡∞§‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞é‡∞≤‡∞æ ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞Ü‡∞∏‡±ç‡∞§‡∞ø ‡∞∞‡∞ø‡∞ú‡∞ø‡∞∏‡±ç‡∞ü‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞µ‡∞æ‡∞∞‡∞∏‡∞§‡±ç‡∞µ ‡∞π‡∞ï‡±ç‡∞ï‡±Å‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞≠‡±Ç‡∞Æ‡∞ø ‡∞µ‡∞ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?",
        "‡∞∏‡∞∞‡±ç‡∞µ‡±á ‡∞∏‡±Ü‡∞ü‡±ç‡∞ü‡∞ø‡∞≤‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞Ö‡∞Ç‡∞ü‡±á ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞Ü‡∞∏‡±ç‡∞§‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡∞ø‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?"
    ],
    "‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞ö‡∞ü‡±ç‡∞ü‡∞Ç": [
        "‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞´‡∞ø‡∞∞‡±ç‡∞Ø‡∞æ‡∞¶‡±Å ‡∞é‡∞≤‡∞æ ‡∞¶‡∞æ‡∞ñ‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞Ü‡∞®‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç ‡∞Æ‡±ã‡∞∏‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞®‡∞ø‡∞µ‡±á‡∞¶‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?",
        "‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞µ‡±Å‡∞≤ ‡∞µ‡∞æ‡∞™‡∞∏‡±Ä ‡∞π‡∞ï‡±ç‡∞ï‡±Å‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞∏‡∞∞‡±ç‡∞µ‡±Ä‡∞∏‡±ç ‡∞õ‡∞æ‡∞∞‡±ç‡∞ú‡±Ä‡∞≤‡∞™‡±à ‡∞´‡∞ø‡∞∞‡±ç‡∞Ø‡∞æ‡∞¶‡±Å ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞¨‡±ç‡∞Ø‡∞æ‡∞Ç‡∞ï‡±Å ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø?"
    ],
    "‡∞ï‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞ï ‡∞ö‡∞ü‡±ç‡∞ü‡∞Ç": [
        "‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó ‡∞µ‡∞ø‡∞°‡∞ø‡∞ö‡∞ø‡∞™‡±Ü‡∞ü‡±ç‡∞ü‡±á ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
        "‡∞Ö‡∞®‡±Å‡∞ï‡±ã‡∞ï‡±Å‡∞Ç‡∞°‡∞æ ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡∞Ç ‡∞ï‡±ã‡∞≤‡±ç‡∞™‡±ã‡∞Ø‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞è‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞ú‡±Ä‡∞§‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞ï‡∞™‡±ã‡∞§‡±á ‡∞è‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "‡∞ï‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞ï ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞Ç‡∞≤‡±ã ‡∞´‡∞ø‡∞∞‡±ç‡∞Ø‡∞æ‡∞¶‡±Å ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?",
        "EPF ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ó‡±ç‡∞∞‡∞æ‡∞ü‡±ç‡∞Ø‡±Ç‡∞ü‡±Ä ‡∞é‡∞≤‡∞æ ‡∞ï‡±ç‡∞≤‡±Ü‡∞Ø‡∞ø‡∞Æ‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø?"
    ]
}

legal_categories_english = {
    "Criminal Law": [
        "What is the process for filing an FIR?",
        "What are the rights of an arrested person?", 
        "How to apply for bail?",
        "What is anticipatory bail?",
        "What are the rights in police custody?",
        "How to report cyber crime?",
        "What to do in case of dowry harassment?"
    ],
    "Civil Law": [
        "How to resolve property disputes?",
        "How to file a contract breach case?",
        "How to obtain an injunction?",
        "How to claim damages?",
        "How to resolve rental disputes?",
        "How to resolve disputes with neighbors?"
    ],
    "Family Law": [
        "What is the divorce process?",
        "What are child custody laws?",
        "How to annul a marriage?",
        "How to get protection from domestic violence?",
        "How to claim maintenance/alimony?",
        "How to register a marriage?"
    ],
    "Property Law": [
        "How to write a will?",
        "What is the property registration process?",
        "What are inheritance rights?",
        "How to resolve land disputes?",
        "What is survey settlement?",
        "What is the property transfer process?"
    ],
    "Consumer Law": [
        "How to file a consumer complaint?",
        "How to report online fraud?",
        "What are product return rights?",
        "How to complain about service charges?",
        "How to resolve banking issues?"
    ],
    "Labor Law": [
        "What is the job resignation process?",
        "What to do when unfairly terminated?",
        "What to do if salary is not paid?",
        "How to file a complaint in labor court?",
        "How to claim EPF and gratuity?"
    ]
}

# Select categories based on language
legal_categories = legal_categories_telugu if st.session_state.language == 'Telugu' else legal_categories_english

# Create layout for better organization
col1, col2 = st.columns([3, 1])

with col1:
    # Category selection
    if st.session_state.language == 'Telugu':
        selected_category = st.selectbox(
            "‡∞µ‡∞∞‡±ç‡∞ó‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:",
            list(legal_categories.keys()),
            help="‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø"
        )
        
        # Question selection
        if selected_category:
            questions = legal_categories[selected_category]
            selected_question = st.selectbox(
                "‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:",
                ["üí¨ ‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡±ç ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø..."] + questions,
                help="‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Ä ‡∞∏‡±ç‡∞µ‡∞Ç‡∞§ ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø"
            )
    else:
        selected_category = st.selectbox(
            "Select Category:",
            list(legal_categories.keys()),
            help="Choose the legal category related to your question"
        )
        
        # Question selection
        if selected_category:
            questions = legal_categories[selected_category]
            selected_question = st.selectbox(
                "Select Question:",
                ["üí¨ Write custom question..."] + questions,
                help="Choose a preset question or write your own custom question"
            )

with col2:
    # Empty space for better layout balance
    st.write("")

# Display recent chat history
if st.session_state.chat_history:
    if st.session_state.language == 'Telugu':
        with st.expander(f"üìú ‡∞á‡∞ü‡±Ä‡∞µ‡∞≤‡∞ø ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞≤‡±Å ({len(st.session_state.chat_history)} ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç)", expanded=False):
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # Show last 5
                st.markdown(f"""
                <div class="chat-message">
                    <small><strong>#{len(st.session_state.chat_history)-i}</strong> | {chat.get('timestamp', '‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞®‡∞ø ‡∞∏‡∞Æ‡∞Ø‡∞Ç')} | {chat.get('category', '‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞®‡∞ø ‡∞µ‡∞∞‡±ç‡∞ó‡∞Ç')}</small><br>
                    <strong>‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®:</strong> {chat.get('question', '‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®')[:100]}{'...' if len(chat.get('question', '')) > 100 else ''}<br>
                    <strong>‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:</strong> {chat.get('response', '‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞®‡∞ø ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç')[:150]}{'...' if len(chat.get('response', '')) > 150 else ''}
                </div>
                """, unsafe_allow_html=True)
    else:
        with st.expander(f"üìú Recent Conversations ({len(st.session_state.chat_history)} total)", expanded=False):
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # Show last 5
                st.markdown(f"""
                <div class="chat-message">
                    <small><strong>#{len(st.session_state.chat_history)-i}</strong> | {chat.get('timestamp', 'Unknown time')} | {chat.get('category', 'Unknown category')}</small><br>
                    <strong>Q:</strong> {chat.get('question', 'Unknown question')[:100]}{'...' if len(chat.get('question', '')) > 100 else ''}<br>
                    <strong>A:</strong> {chat.get('response', 'Unknown response')[:150]}{'...' if len(chat.get('response', '')) > 150 else ''}
                </div>
                """, unsafe_allow_html=True)

# Input area
if st.session_state.language == 'Telugu':
    if selected_question == "üí¨ ‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡±ç ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø...":
        user_query = st.text_area(
            "‚úçÔ∏è ‡∞Æ‡±Ä ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:",
            height=120,
            placeholder="‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£: ‡∞®‡∞æ‡∞ï‡±Å ‡∞í‡∞ï ‡∞á‡∞Ç‡∞ü‡±ç‡∞≤‡±ã ‡∞µ‡∞ø‡∞µ‡∞æ‡∞¶‡∞Ç ‡∞â‡∞Ç‡∞¶‡∞ø, ‡∞®‡±á‡∞®‡±Å ‡∞è‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø? ‡∞≤‡±á‡∞¶‡∞æ ‡∞®‡∞æ ‡∞â‡∞¶‡±ç‡∞Ø‡±ã‡∞ó‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø...",
            help="‡∞Æ‡±Ä ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø"
        )
    else:
        user_query = selected_question
        st.text_area("‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞® ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®:", value=selected_question, height=100, disabled=True)
else:
    if selected_question == "üí¨ Write custom question...":
        user_query = st.text_area(
            "‚úçÔ∏è Type your legal question here:",
            height=120,
            placeholder="Example: I have a property dispute, what should I do? Or I'm facing issues at my workplace...",
            help="Please write your legal question clearly in English"
        )
    else:
        user_query = selected_question
        st.text_area("Selected Question:", value=selected_question, height=100, disabled=True)

# Load models and translator with optimizations for 8GB RAM
@st.cache_resource
def load_translator():
    """Load Google Translator with error handling"""
    try:
        translator = Translator()
        # Test translation to ensure it works
        test_translation = translator.translate("test", src='en', dest='te')
        if test_translation and test_translation.text:
            return translator
        else:
            raise Exception("Translation test failed")
    except Exception:
        st.error("Translation service error. Please check your internet connection and try again.")
        return None

@st.cache_resource
def load_optimized_model(model_choice="Auto"):
    """Load the best model optimized for 8GB RAM with progress tracking"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Model selection based on choice and available memory
        if model_choice == "Auto" or model_choice == "DialoGPT-Large":
            model_name = "microsoft/DialoGPT-large"
        elif model_choice == "FLAN-T5-Base":
            model_name = "google/flan-t5-base"
        else:
            model_name = "microsoft/DialoGPT-large"
        
        status_text.text(f"üîÑ Loading {model_name}...")
        progress_bar.progress(20)
        
        # Check available memory and adjust accordingly
        device = "cuda" if torch.cuda.is_available() else "cpu"
        status_text.text(f"üîÑ Detected device: {device}")
        progress_bar.progress(40)
        
        # Load tokenizer
        status_text.text("üîÑ Loading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        progress_bar.progress(60)
        
        # Load model with memory optimization
        status_text.text("üîÑ Loading model...")
        if "flan-t5" in model_name.lower():
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True
            )
            task = "text2text-generation"
        else:
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                low_cpu_mem_usage=True,
                device_map="auto" if device == "cuda" else None
            )
            task = "text-generation"
        
        progress_bar.progress(80)
        
        # Create pipeline with optimizations
        status_text.text("üîÑ Creating pipeline...")
        pipe = pipeline(
            task,
            model=model,
            tokenizer=tokenizer,
            device=0 if device == "cuda" else -1,
            batch_size=1,
            max_length=512 if "flan-t5" in model_name.lower() else None,
            max_new_tokens=None if "flan-t5" in model_name.lower() else 512
        )
        
        progress_bar.progress(100)
        status_text.text("‚úÖ Model loaded successfully!")
        
        # Clean up progress indicators
        progress_bar.empty()
        status_text.empty()
        
        model_type = "FLAN-T5-Base" if "flan-t5" in model_name.lower() else "DialoGPT-Large"
        return pipe, model_type
        
    except Exception:
        progress_bar.progress(100)
        status_text.text("‚ùå Loading failed, trying fallback...")
        
        # Fallback to smaller model if large model fails
        try:
            st.warning("‚ö†Ô∏è Primary model failed. Loading backup model...")
            fallback_model = "google/flan-t5-small"
            
            tokenizer = AutoTokenizer.from_pretrained(fallback_model)
            model = AutoModelForCausalLM.from_pretrained(
                fallback_model,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True
            )
            
            pipe = pipeline(
                "text2text-generation",
                model=model,
                tokenizer=tokenizer,
                device=-1,
                max_length=512
            )
            
            progress_bar.empty()
            status_text.empty()
            st.success("‚úÖ Fallback model loaded successfully!")
            
            return pipe, "FLAN-T5-Small (Fallback)"
            
        except Exception:
            progress_bar.empty()
            status_text.empty()
            st.error("‚ùå All models failed to load. Please try refreshing the page or check your internet connection.")
            return None, None

def create_advanced_legal_prompt(query, category="General"):
    """Create a specialized prompt for legal queries with Indian context"""
    return f"""You are an expert Indian legal consultant specializing in {category} with comprehensive knowledge of:

LEGAL FRAMEWORK:
- Indian Constitution (Articles, Fundamental Rights & Duties)
- Indian Penal Code (IPC) & Bharatiya Nyaya Sanhita (BNS) 2023
- Criminal Procedure Code (CrPC) & Bharatiya Nagarik Suraksha Sanhita (BNSS) 2023
- Civil Procedure Code (CPC) & Evidence Act
- Family laws: Hindu Marriage Act, Special Marriage Act, Muslim Personal Law
- Property laws: Transfer of Property Act, Registration Act
- Consumer Protection Act 2019 & Labor Laws
- Recent Supreme Court & High Court judgments

RESPONSE REQUIREMENTS:
1. ‚úÖ Provide accurate, practical legal guidance
2. üìã Include relevant legal sections/acts when applicable
3. üîÑ Give step-by-step procedural guidance
4. ‚è∞ Mention approximate timelines and costs
5. üìÑ List required documents and forms
6. ‚öñÔ∏è Reference landmark judgments if relevant
7. üèõÔ∏è Suggest appropriate courts/forums
8. ‚ö†Ô∏è Always recommend consulting qualified lawyers for specific cases

CATEGORY: {category}
QUERY: {query}

Provide comprehensive legal guidance in clear, professional English:"""

def generate_legal_response(model_pipeline, query, model_type, category="General"):
    """Generate response using the loaded model with enhanced parameters"""
    try:
        legal_prompt = create_advanced_legal_prompt(query, category)
        
        # Enhanced generation parameters
        generation_params = {
            "temperature": 0.7,
            "do_sample": True,
            "repetition_penalty": 1.2,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 3
        }
        
        if "flan-t5" in model_type.lower():
            # T5 model parameters
            response = model_pipeline(
                legal_prompt,
                max_length=600,
                min_length=100,
                **generation_params
            )
            generated_text = response[0]['generated_text']
        else:
            # GPT model parameters
            response = model_pipeline(
                legal_prompt,
                max_new_tokens=500,
                min_length=len(legal_prompt) + 50,
                pad_token_id=model_pipeline.tokenizer.eos_token_id,
                eos_token_id=model_pipeline.tokenizer.eos_token_id,
                return_full_text=False,
                **generation_params
            )
            generated_text = response[0]['generated_text']
        
        # Post-process the response
        generated_text = generated_text.strip()
        
        # Add standard legal disclaimer if not present
        if "consult" not in generated_text.lower() and "lawyer" not in generated_text.lower():
            generated_text += "\n\n‚ö†Ô∏è IMPORTANT: This is general information only. Please consult a qualified lawyer for advice specific to your situation."
        
        return generated_text
        
    except Exception as e:
        error_msg = f"Response generation error: {str(e)}. Please try again or rephrase your question."
        st.error(error_msg)
        return error_msg

def translate_with_fallback(translator, text, src_lang, dest_lang, max_retries=3):
    """Translate text with retry mechanism and fallback"""
    for attempt in range(max_retries):
        try:
            if translator:
                result = translator.translate(text, src=src_lang, dest=dest_lang)
                if result and result.text:
                    return result.text
            raise Exception("Translation failed")
        except Exception:
            if attempt < max_retries - 1:
                st.warning(f"Translation attempt {attempt + 1} failed, retrying...")
                continue
            else:
                st.error(f"Translation failed after {max_retries} attempts.")
                return text  # Return original text if translation fails

def process_query_telugu():
    # Create containers for dynamic updates
    status_container = st.container()
    result_container = st.container()
    
    with status_container:
        # Initialize progress tracking
        progress_col1, progress_col2 = st.columns([3, 1])
        with progress_col1:
            overall_progress = st.progress(0)
            status_text = st.empty()
        with progress_col2:
            step_counter = st.empty()
        
        # Step 1: Load translator
        step_counter.text("‡∞¶‡∞∂ 1/4")
        status_text.text("üîÑ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(10)
        
        if not st.session_state.translator:
            st.session_state.translator = load_translator()
        
        if not st.session_state.translator:
            st.error("‚ùå ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä ‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‡∞®‡±Ü‡∞ü‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.")
            st.stop()
        
        overall_progress.progress(25)
        status_text.text("‚úÖ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç")
        
        # Step 2: Load AI model
        step_counter.text("‡∞¶‡∞∂ 2/4")
        status_text.text("üîÑ AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(30)
        
        if not st.session_state.model_loaded or st.session_state.current_model is None:
            model_pipeline, model_type = load_optimized_model(model_choice)
            if model_pipeline:
                st.session_state.current_model = (model_pipeline, model_type)
                st.session_state.model_loaded = True
            else:
                st.error("‚ùå AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞≤‡±ã‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞µ‡∞ø‡∞´‡∞≤‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞™‡±á‡∞ú‡±Ä‡∞®‡∞ø ‡∞∞‡∞ø‡∞´‡±ç‡∞∞‡±Ü‡∞∑‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.")
                st.stop()
        else:
            model_pipeline, model_type = st.session_state.current_model
        
        overall_progress.progress(50)
        status_text.text(f"‚úÖ AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç: {model_type}")
        
        # Step 3: Process query
        step_counter.text("‡∞¶‡∞∂ 3/4")
        status_text.text("üîÑ ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(60)
        
        try:
            # Translate Telugu to English if needed
            if user_query != selected_question or any(char in user_query for char in '‡∞Ö‡∞Ü‡∞á‡∞à‡∞â‡∞ä‡∞ã‡∞å‡∞é‡∞è‡∞ê‡∞í‡∞ì‡∞î‡∞ï‡∞ñ‡∞ó‡∞ò'):
                status_text.text("üîÑ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‚Üí ‡∞á‡∞Ç‡∞ó‡±ç‡∞≤‡±Ä‡∞∑‡±ç ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
                translated_query = translate_with_fallback(
                    st.session_state.translator, user_query, 'te', 'en'
                )
            else:
                translated_query = user_query
            
            overall_progress.progress(70)
            
            # Generate AI response
            status_text.text("ü§ñ AI ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞ï‡∞§‡±ç‡∞µ‡∞Ç ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø...")
            english_response = generate_legal_response(
                model_pipeline, translated_query, model_type, selected_category
            )
            
            overall_progress.progress(85)
            
            # Translate response to Telugu
            status_text.text("üîÑ ‡∞á‡∞Ç‡∞ó‡±ç‡∞≤‡±Ä‡∞∑‡±ç ‚Üí ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
            telugu_response = translate_with_fallback(
                st.session_state.translator, english_response, 'en', 'te'
            )
            
            overall_progress.progress(95)
            
            # Save to chat history
            chat_entry = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "category": selected_category,
                "question": user_query,
                "translated_question": translated_query,
                "response": telugu_response,
                "english_response": english_response,
                "model_used": model_type,
                "response_language": "Telugu"
            }
            st.session_state.chat_history.append(chat_entry)
            
            overall_progress.progress(100)
            status_text.text("‚úÖ ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø!")
            
            # Clear progress indicators after a short delay
            time.sleep(1)
            status_container.empty()
            
        except Exception as e:
            overall_progress.progress(100)
            status_text.text("‚ùå ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞µ‡∞ø‡∞´‡∞≤‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø")
            st.error(f"‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {str(e)}")
            st.info("‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ‡∞≤‡∞ï‡±Å ‡∞Æ‡±Ä ‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‡∞®‡±Ü‡∞ü‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.")
            st.stop()
    
    # Display results in Telugu
    with result_container:
        st.markdown("### üìò ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:")
        
        if telugu_response:
            st.markdown(f"""
            <div class="assistant-message">
                <strong>‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®:</strong> {user_query}<br><br>
                <strong>‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:</strong> {telugu_response}<br><br>
                <small><em>AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç: {model_type} | ‡∞µ‡∞∞‡±ç‡∞ó‡∞Ç: {selected_category} | ‡∞∏‡∞Æ‡∞Ø‡∞Ç: {datetime.now().strftime("%H:%M:%S")}</em></small>
            </div>
            """, unsafe_allow_html=True)
        
        # Action buttons in Telugu
        st.markdown("### üéØ ‡∞§‡±ç‡∞µ‡∞∞‡∞ø‡∞§ ‡∞ö‡∞∞‡±ç‡∞Ø‡∞≤‡±Å")
        action_col1, action_col2, action_col3, action_col4 = st.columns(4)
        
        with action_col1:
            if st.button("üìã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞ï‡∞æ‡∞™‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø"):
                st.code(telugu_response, language="text")
                st.success("‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞ï‡∞æ‡∞™‡±Ä ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç!")
        
        with action_col2:
            if st.button("üîÑ ‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø"):
                st.info("‡∞™‡±à‡∞® ‡∞Æ‡±Ä ‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä '‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø' ‡∞ï‡±ç‡∞≤‡∞ø‡∞ï‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø!")
        
        with action_col3:
            if st.button("‚≠ê ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡±á‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø"):
                rating = st.select_slider("‡∞à ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡±á‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø:", options=[1, 2, 3, 4, 5], value=4)
                st.success(f"‡∞∞‡±á‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞á‡∞ö‡±ç‡∞ö‡∞ø‡∞®‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å: {rating}/5 ‡∞®‡∞ï‡±ç‡∞∑‡∞§‡±ç‡∞∞‡∞æ‡∞≤‡±Å!")
        
        with action_col4:
            if st.button("üö® ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞®‡∞ø‡∞µ‡±á‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø"):
                st.warning("‡∞®‡∞ø‡∞∞‡±ç‡∞¶‡∞ø‡∞∑‡±ç‡∞ü ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡∞ï‡±Å ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Ö‡∞∞‡±ç‡∞π‡∞§ ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞® ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø‡∞µ‡∞æ‡∞¶‡∞ø‡∞®‡∞ø ‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.")


def process_query_english():
    # Create containers for dynamic updates
    status_container = st.container()
    result_container = st.container()
    
    with status_container:
        # Initialize progress tracking
        progress_col1, progress_col2 = st.columns([3, 1])
        with progress_col1:
            overall_progress = st.progress(0)
            status_text = st.empty()
        with progress_col2:
            step_counter = st.empty()
        
        # Step 1: Load translator (optional for English)
        step_counter.text("Step 1/4")
        status_text.text("üîÑ Loading translation service...")
        overall_progress.progress(10)
        
        if not st.session_state.translator:
            st.session_state.translator = load_translator()
        
        overall_progress.progress(25)
        status_text.text("‚úÖ Translation service ready")
        
        # Step 2: Load AI model
        step_counter.text("Step 2/4")
        status_text.text("üîÑ Loading AI model...")
        overall_progress.progress(30)
        
        if not st.session_state.model_loaded or st.session_state.current_model is None:
            model_pipeline, model_type = load_optimized_model(model_choice)
            if model_pipeline:
                st.session_state.current_model = (model_pipeline, model_type)
                st.session_state.model_loaded = True
            else:
                st.error("‚ùå AI model loading failed. Please refresh the page and try again.")
                st.stop()
        else:
            model_pipeline, model_type = st.session_state.current_model
        
        overall_progress.progress(50)
        status_text.text(f"‚úÖ AI model ready: {model_type}")
        
        # Step 3: Process query
        step_counter.text("Step 3/4")
        status_text.text("üîÑ Processing your question...")
        overall_progress.progress(60)
        
        try:
            overall_progress.progress(70)
            
            # Generate AI response
            status_text.text("ü§ñ AI generating legal guidance...")
            english_response = generate_legal_response(
                model_pipeline, user_query, model_type, selected_category
            )
            
            overall_progress.progress(95)
            
            # Save to chat history
            chat_entry = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "category": selected_category,
                "question": user_query,
                "translated_question": user_query,
                "response": english_response,
                "english_response": english_response,
                "model_used": model_type,
                "response_language": "English"
            }
            st.session_state.chat_history.append(chat_entry)
            
            overall_progress.progress(100)
            status_text.text("‚úÖ Response generated successfully!")
            
            # Clear progress indicators after a short delay
            time.sleep(1)
            status_container.empty()
            
        except Exception as e:
            overall_progress.progress(100)
            status_text.text("‚ùå Processing failed")
            st.error(f"Processing error: {str(e)}")
            st.info("Please try again or check your internet connection.")
            st.stop()
    
    # Display results in English
    with result_container:
        st.markdown("### üìò Legal Response:")
        
        if english_response:
            st.markdown(f"""
            <div class="user-message">
                <strong>Question:</strong> {user_query}<br><br>
                <strong>Answer:</strong> {english_response}<br><br>
                <small><em>AI Model: {model_type} | Category: {selected_category} | Time: {datetime.now().strftime("%H:%M:%S")}</em></small>
            </div>
            """, unsafe_allow_html=True)
        
        # Action buttons in English
        st.markdown("### üéØ Quick Actions")
        action_col1, action_col2, action_col3, action_col4 = st.columns(4)
        
        with action_col1:
            if st.button("üìã Copy Response"):
                st.code(english_response, language="text")
                st.success("Response ready to copy!")
        
        with action_col2:
            if st.button("üîÑ Ask Follow-up"):
                st.info("Type your follow-up question above and click 'Get Answer' again!")
        
        with action_col3:
            if st.button("‚≠ê Rate Response"):
                rating = st.select_slider("Rate this response:", options=[1, 2, 3, 4, 5], value=4)
                st.success(f"Thank you for rating: {rating}/5 stars!")
        
        with action_col4:
            if st.button("üö® Report Issue"):
                st.warning("Please ensure to consult a qualified lawyer for specific legal issues.")


# Main processing
col1, col2, col3 = st.columns([1, 2, 1])

with col2:
    if st.session_state.language == 'Telugu':
        if st.button("üí¨ ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø", type="primary", use_container_width=True):
            if not user_query.strip():
                st.warning("‚ö†Ô∏è ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞®‡∞Æ‡±ã‡∞¶‡±Å ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø")
            else:
                process_query_telugu()
    else:
        if st.button("üí¨ Get Answer", type="primary", use_container_width=True):
            if not user_query.strip():
                st.warning("‚ö†Ô∏è Please enter a question")
            else:
                process_query_english()



# Legal disclaimer section
st.markdown("---")
st.subheader("‚ö†Ô∏è Important Legal Disclaimer" if st.session_state.language == 'English' else "‚ö†Ô∏è ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞®‡∞ø‡∞∞‡∞æ‡∞ï‡∞∞‡∞£")

# Use columns for better layout
disclaimer_col1, disclaimer_col2 = st.columns(2)

with disclaimer_col1:
    st.markdown("#### üî¥ Important Limitations")
    st.info("""
    ‚Ä¢ **General Information Only**: This AI provides general legal information, not personalized legal advice
    
    ‚Ä¢ **Not a Lawyer**: This system cannot replace consultation with qualified legal professionals
    
    ‚Ä¢ **Accuracy**: While we strive for accuracy, legal information may change or vary by jurisdiction
    
    ‚Ä¢ **No Attorney-Client Relationship**: Using this service does not create any legal relationship
    """)
    
    st.markdown("#### üìû Emergency Legal Help")
    st.warning("""
    ‚Ä¢ **National Legal Services Authority**: 15100 (Toll-free)
    
    ‚Ä¢ **Women Helpline**: 181
    
    ‚Ä¢ **Child Helpline**: 1098
    
    ‚Ä¢ **Cyber Crime**: 1930
    
    ‚Ä¢ **Police**: 100
    """)

with disclaimer_col2:
    st.markdown("#### ‚úÖ When to Consult a Lawyer")
    st.success("""
    ‚Ä¢ **Before filing any legal case** or application
    
    ‚Ä¢ **When drafting important legal documents**
    
    ‚Ä¢ **If you're involved in any legal dispute**
    
    ‚Ä¢ **For interpretation of specific laws** to your situation
    
    ‚Ä¢ **Before making important legal decisions**
    """)
    
    st.markdown("#### ÔøΩ Application Statistics")
    st.info("""
    ‚Ä¢ **Total Categories**: 6 Legal Areas
    
    ‚Ä¢ **Preset Questions**: 32+ Sample Questions
    
    ‚Ä¢ **AI Models**: 3 Advanced Models
    
    ‚Ä¢ **Languages**: English Support
    """)

# Final reminder
st.error("üèõÔ∏è **Remember**: 'Justice delayed is justice denied' - Seek timely legal help when needed!")

# Footer
if st.session_state.language == 'Telugu':
    st.markdown("""
    <div style="text-align: center; margin: 2rem 0; padding: 1rem; background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-radius: 10px; border: 1px solid #2196f3;">
        <small style="color: #1976d2;">
            ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞ï‡∞§‡±ç‡∞µ‡∞Ç ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç ‚ù§Ô∏è‡∞§‡±ã ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø | ‡∞µ‡±Ü‡∞∞‡±ç‡∞∑‡∞®‡±ç 2.1 ‡∞Æ‡±Ü‡∞∞‡±Å‡∞ó‡±Å‡∞™‡∞∞‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø | ‡∞¶‡±ç‡∞µ‡∞ø‡∞≠‡∞æ‡∞∑ ‡∞é‡∞°‡∞ø‡∞∑‡∞®‡±ç
        </small>
    </div>
    """, unsafe_allow_html=True)
else:
    st.markdown("""
    <div style="text-align: center; margin: 2rem 0; padding: 1rem; background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-radius: 10px; border: 1px solid #2196f3;">
        <small style="color: #1976d2;">
            Developed with ‚ù§Ô∏è to provide accessible legal guidance | Version 2.1 Enhanced | Bilingual Edition
        </small>
    </div>
    """, unsafe_allow_html=True)