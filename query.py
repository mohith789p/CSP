import streamlit as st
from datetime import datetime
import time
from utils import translate_with_fallback
from prompts import generate_legal_response
from models import load_translator, load_optimized_model

def process_query_telugu(user_query, selected_category, model_choice):
    status_container = st.container()
    result_container = st.container()

    with status_container:
        progress_col1, progress_col2 = st.columns([3,1])
        with progress_col1:
            overall_progress = st.progress(0)
            status_text = st.empty()
        with progress_col2:
            step_counter = st.empty()

        # Step 1: Load translator
        step_counter.text("‡∞¶‡∞∂ 1/4")
        status_text.text("üîÑ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(10)

        if not st.session_state.translator:
            st.session_state.translator = load_translator()

        if not st.session_state.translator:
            st.error("‚ùå ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä ‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‡∞®‡±Ü‡∞ü‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.")
            st.stop()

        overall_progress.progress(25)
        status_text.text("‚úÖ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç")

        # Step 2: Load AI model
        step_counter.text("‡∞¶‡∞∂ 2/4")
        status_text.text("üîÑ AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(30)

        if not st.session_state.model_loaded or st.session_state.current_model is None:
            model_pipeline, model_type = load_optimized_model(model_choice)
            if model_pipeline:
                st.session_state.current_model = (model_pipeline, model_type)
                st.session_state.model_loaded = True
            else:
                st.error("‚ùå AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞≤‡±ã‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞µ‡∞ø‡∞´‡∞≤‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞™‡±á‡∞ú‡±Ä‡∞®‡∞ø ‡∞∞‡∞ø‡∞´‡±ç‡∞∞‡±Ü‡∞∑‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.")
                st.stop()
        else:
            model_pipeline, model_type = st.session_state.current_model

        overall_progress.progress(50)
        status_text.text(f"‚úÖ AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç: {model_type}")

        # Step 3: Process query
        step_counter.text("‡∞¶‡∞∂ 3/4")
        status_text.text("üîÑ ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
        overall_progress.progress(60)

        try:
            # Translate Telugu to English if needed
            if user_query != "" and any(char in user_query for char in '‡∞Ö‡∞Ü‡∞á‡∞à‡∞â‡∞ä‡∞ã‡∞å‡∞é‡∞è‡∞ê‡∞í‡∞ì‡∞î‡∞ï‡∞ñ‡∞ó‡∞ò'):
                status_text.text("üîÑ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‚Üí ‡∞á‡∞Ç‡∞ó‡±ç‡∞≤‡±Ä‡∞∑‡±ç ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
                translated_query = translate_with_fallback(
                    st.session_state.translator, user_query, 'te', 'en'
                )
            else:
                translated_query = user_query

            overall_progress.progress(70)

            # Generate AI response
            status_text.text("ü§ñ AI ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞ï‡∞§‡±ç‡∞µ‡∞Ç ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞¶‡∞ø...")
            english_response = generate_legal_response(
                model_pipeline, translated_query, model_type, selected_category
            )

            overall_progress.progress(85)

            # Translate response to Telugu
            status_text.text("üîÑ ‡∞á‡∞Ç‡∞ó‡±ç‡∞≤‡±Ä‡∞∑‡±ç ‚Üí ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç...")
            telugu_response = translate_with_fallback(
                st.session_state.translator, english_response, 'en', 'te'
            )

            overall_progress.progress(95)

            # Save to chat history
            chat_entry = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "category": selected_category,
                "question": user_query,
                "translated_question": translated_query,
                "response": telugu_response,
                "english_response": english_response,
                "model_used": model_type,
                "response_language": "Telugu"
            }
            st.session_state.chat_history.append(chat_entry)

            overall_progress.progress(100)
            status_text.text("‚úÖ ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø!")

            time.sleep(1)
            status_container.empty()

        except Exception as e:
            overall_progress.progress(100)
            status_text.text("‚ùå ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞µ‡∞ø‡∞´‡∞≤‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø")
            st.error(f"‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {str(e)}")
            st.info("‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ‡∞≤‡∞ï‡±Å ‡∞Æ‡±Ä ‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‡∞®‡±Ü‡∞ü‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.")
            st.stop()

    with result_container:
        st.markdown("### üìò ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:")
        if telugu_response:
            st.markdown(f"""
            <div class="assistant-message">
                <strong>‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®:</strong> {user_query}<br><br>
                <strong>‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:</strong> {telugu_response}<br><br>
                <small><em>AI ‡∞Æ‡±ã‡∞°‡∞≤‡±ç: {model_type} | ‡∞µ‡∞∞‡±ç‡∞ó‡∞Ç: {selected_category} | ‡∞∏‡∞Æ‡∞Ø‡∞Ç: {datetime.now().strftime("%H:%M:%S")}</em></small>
            </div>
            """, unsafe_allow_html=True)

        # (Action buttons left as is in main or UI modules)


def process_query_english(user_query, selected_category, model_choice):
    status_container = st.container()
    result_container = st.container()

    with status_container:
        progress_col1, progress_col2 = st.columns([3,1])
        with progress_col1:
            overall_progress = st.progress(0)
            status_text = st.empty()
        with progress_col2:
            step_counter = st.empty()

        step_counter.text("Step 1/4")
        status_text.text("üîÑ Loading translation service...")
        overall_progress.progress(10)

        if not st.session_state.translator:
            st.session_state.translator = load_translator()

        overall_progress.progress(25)
        status_text.text("‚úÖ Translation service ready")

        step_counter.text("Step 2/4")
        status_text.text("üîÑ Loading AI model...")
        overall_progress.progress(30)

        if not st.session_state.model_loaded or st.session_state.current_model is None:
            model_pipeline, model_type = load_optimized_model(model_choice)
            if model_pipeline:
                st.session_state.current_model = (model_pipeline, model_type)
                st.session_state.model_loaded = True
            else:
                st.error("‚ùå AI model loading failed. Please refresh the page and try again.")
                st.stop()
        else:
            model_pipeline, model_type = st.session_state.current_model

        overall_progress.progress(50)
        status_text.text(f"‚úÖ AI model ready: {model_type}")

        step_counter.text("Step 3/4")
        status_text.text("üîÑ Processing your question...")
        overall_progress.progress(60)

        try:
            overall_progress.progress(70)
            status_text.text("ü§ñ AI generating legal guidance...")
            english_response = generate_legal_response(
                model_pipeline, user_query, model_type, selected_category
            )

            overall_progress.progress(95)

            chat_entry = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "category": selected_category,
                "question": user_query,
                "translated_question": user_query,
                "response": english_response,
                "english_response": english_response,
                "model_used": model_type,
                "response_language": "English"
            }
            st.session_state.chat_history.append(chat_entry)

            overall_progress.progress(100)
            status_text.text("‚úÖ Response generated successfully!")

            time.sleep(1)
            status_container.empty()

        except Exception as e:
            overall_progress.progress(100)
            status_text.text("‚ùå Processing failed")
            st.error(f"Processing error: {str(e)}")
            st.info("Please try again or check your internet connection.")
            st.stop()

    with result_container:
        st.markdown("### üìò Legal Response:")
        if english_response:
            st.markdown(f"""
            <div class="user-message">
                <strong>Question:</strong> {user_query}<br><br>
                <strong>Answer:</strong> {english_response}<br><br>
                <small><em>AI Model: {model_type} | Category: {selected_category} | Time: {datetime.now().strftime("%H:%M:%S")}</em></small>
            </div>
            """, unsafe_allow_html=True)

        # (Action buttons left as is in main or UI modules)
